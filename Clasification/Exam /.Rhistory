library(openxlsx)
data <- read.xlsx("./data/BDexamen2.xlsx")
View(data)
dim(data)
dim(data)
str(data)
data$cat2 <- as.factor(data$cat2)
data$cat3 <- as.factor(data$cat3)
data$TAMAMU <- as.factor(data$TAMAMU)
data$SEXO <- as.factor(data$SEXO)
data$ESTUD <- as.factor(data$ESTUD)
data$LAB <- as.factor(data$LAB)
data$REGTEN <- as.factor(data$REGTEN)
unique(data$EDAD)
unique(data$EDAD)
data$EDAD <- as.integer(data$EDAD)
View(data)
str(data)
data$DENSIDAD <- as.factor(data$DENSIDAD)
str(data)
numeric <- data[,c(3, 8,9)]
summary(numeric_A)
numeric <- data[,c(3, 8,9)]
summary(numeric)
numeric_stats <- data.frame(
Min = apply(numeric, 2, min), # mín
Q1 = apply(numeric, 2, quantile, 1/4), # 1er cuartil
Med = apply(numeric, 2, median), # mediana
Mean = apply(numeric, 2, mean), # media
Q3 = apply(numeric, 2, quantile, 3/4), # 3er cuartil
Max = apply(numeric, 2, max), # Máx
Var = apply(numeric, 2, var)
)
numeric <- data[,c(3, 8,9)]
summary(numeric)
cualitative <- data[, c(1,2,4:7,10,11)]
cualitative <- data[, c(1,2,4:7,10,11)]
summary(cualitative)
library(mvnormtest)
mshapiro.test(numeric)
library(mvnormtest)
mshapiro.test(numeric$EDAD)
library(mvnormtest)
mshapiro.test(as.matrix(numeric))
sum(is.na(data))
data$SUPERF[is.na(data$SUPERF)] <- mean(data$SUPERF,na.rm = T)
library(mvnormtest)
norm <- data[,c(3, 8,9)]
mshapiro.test(norm)
set.seed(1234)
train <- sample(nrow(data), 0.7*nrow(data))
data.train <- data[train,]
data.test <- data[-train,]
table(data.train$cat2)
table(data.validate$cat2)
table(data.train$cat2)
table(data.test$cat2)
model <- glm(cat2 ~.,family = binomial(link = 'logit'),data = data.train)
basic.model <- glm(cat2 ~.,family = binomial(link = 'logit'),data = data.train)
summary(basic.model)
refined.model <- glm(cat2 ~ SEXO + ESTUD + LAB + REGTEN + IMPEXAC,family = binomial(link = 'logit'),data = data.train)
summary(refined.model)
refined.model <- glm(cat2 ~ SEXO + ESTUD + LAB + REGTEN + IMPEXAC + DENSIDAD,family = binomial(link = 'logit'),data = data.train)
summary(refined.model)
summary(refined.model)
refined.model <- glm(cat2 ~ SEXO + ESTUD + LAB + REGTEN + IMPEXAC,family = binomial(link = 'logit'),data = data.train)
summary(refined.model)
refined.model <- glm(cat2 ~ SEXO + ESTUD + LAB + REGTEN + IMPEXAC + cat3,family = binomial(link = 'logit'),data = data.train)
summary(refined.model)
basic.model <- glm(cat2 ~. -cat3 ,family = binomial(link = 'logit'),data = data.train)
summary(basic.model)
refined.model <- glm(cat2 ~ SEXO + ESTUD + LAB + REGTEN + IMPEXAC,family = binomial(link = 'logit'),data = data.train)
summary(refined.model)
basic.model <- glm(cat2 ~.,family = binomial(link = 'logit'),data = data.train)
summary(basic.model)
refined.model <- glm(cat2 ~ SEXO + ESTUD + LAB + REGTEN + IMPEXAC + cat3,family = binomial(link = 'logit'),data = data.train)
summary(refined.model)
anova(refined.model, test = "Chisq")
pruebilla <- glm(cat2 ~ SEXO + LAB + REGTEN + IMPEXAC + cat3,family = binomial(link = 'logit'),data = data.train)
summary(pruebilla)
anova(refined.model, test = "Chisq")
refined.model2 <- glm(cat2 ~ SEXO + LAB + REGTEN + IMPEXAC + cat3,family = binomial(link = 'logit'),data = data.train)
summary(refined.model2)
anova(refined.model2, test = "Chisq")
library(pscl)
pR2(basic.model)
pR2(refined.model)
pR2(refined.model2)
fitted.results <- predict(refined.model2, newdata = data.test, type = 'response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
fitted.results <- factor(fitted.results, levels = c(0,1), labels = c("No", "Sí"))
(logit.perf <- table(data.test$Poverty_risk, fitted.results, dnn = c("Actual", "Predicted")))
fitted.results <- predict(refined.model2, newdata = data.test, type = 'response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
fitted.results <- factor(fitted.results, levels = c(0,1), labels = c("No", "Sí"))
(logit.perf <- table(data.test$cat2, fitted.results, dnn = c("Actual", "Predicted")))
print(paste('Accuracy',sum(diag(logit.perf))/sum(logit.perf)))
library(pROC)
resRoc <- roc(data.train$cat2 ~ refined.model2$fitted.values)
plot(resRoc, legacy.axes = TRUE)
library(rms)
auc(data.test$cat2, fitted.results)
library(rms)
auc(data.test$cat2, as.numeric(fitted.results)
library(rms)
auc(data.test$cat2, as.numeric(fitted.results))
library(pROC)
resRoc <- roc(data.test$cat2 ~ fitted.results)
library(pROC)
resRoc <- roc(data.test$cat2 ~ as.numeric(fitted.results))
plot(resRoc, legacy.axes = TRUE)
library(rms)
auc(predictions$survived, predictions$pred)
library(pROC)
resRoc <- roc(data.test$cat2 ~ as.numeric(fitted.results))
plot(resRoc, legacy.axes = TRUE)
library(rms)
auc(data.test$cat2, as.numeric(fitted.results))
anova(refined.model2, test = "Chisq")
exp(coef(refined.model2))
coef(refined.model2)
exp(coef(refined.model2))
library(openxlsx)
data <- read.xlsx("./data/BDexamen2.xlsx")
dim(data)
str(data)
data$cat2 <- as.factor(data$cat2)
data$cat3 <- as.factor(data$cat3)
data$DENSIDAD <- as.factor(data$DENSIDAD)
data$TAMAMU <- as.factor(data$TAMAMU)
data$SEXO <- as.factor(data$SEXO)
data$ESTUD <- as.factor(data$ESTUD)
data$LAB <- as.factor(data$LAB)
data$REGTEN <- as.factor(data$REGTEN)
unique(data$EDAD)
data$EDAD <- as.integer(data$EDAD)
str(data)
numeric <- data[,c(3, 8,9)]
summary(numeric)
cualitative <- data[, c(1,2,4:7,10,11)]
summary(cualitative)
data$SUPERF[is.na(data$SUPERF)] <- mean(data$SUPERF,na.rm = T)
set.seed(1234)
train <- sample(nrow(data), 0.7*nrow(data))
data.train <- data[train,]
data.test <- data[-train,]
table(data.train$cat2)
table(data.test$cat2)
basic.model <- glm(cat2 ~.,family = binomial(link = 'logit'),data = data.train)
summary(basic.model)
refined.model <- glm(cat2 ~ SEXO + ESTUD + LAB + REGTEN + IMPEXAC + cat3,family = binomial(link = 'logit'),data = data.train)
summary(refined.model)
anova(refined.model, test = "Chisq")
refined.model2 <- glm(cat2 ~ SEXO + LAB + REGTEN + IMPEXAC + cat3,family = binomial(link = 'logit'),data = data.train)
summary(refined.model2)
anova(refined.model2, test = "Chisq")
library(pscl)
pR2(basic.model)
pR2(refined.model)
pR2(refined.model2)
library(pROC)
resRoc <- roc(data.train$cat2 ~ refined.model2$fitted.values)
plot(resRoc, legacy.axes = TRUE)
library(rms)
auc(data.test$cat2, as.numeric(fitted.results))
fitted.results <- predict(refined.model2, newdata = data.test, type = 'response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
fitted.results <- factor(fitted.results, levels = c(0,1), labels = c("No", "Sí"))
(logit.perf <- table(data.test$cat2, fitted.results, dnn = c("Actual", "Predicted")))
print(paste('Accuracy',sum(diag(logit.perf))/sum(logit.perf)))
library(pROC)
resRoc <- roc(data.test$cat2 ~ as.numeric(fitted.results))
plot(resRoc, legacy.axes = TRUE)
library(rms)
auc(data.test$cat2, as.numeric(fitted.results))
anova(refined.model2, test = "Chisq")
exp(coef(refined.model2))
coef(refined.model2)
contrast(data$SEXO)
contrasts(data$SEXO)
refined.model57 <- glm(cat2 ~ SEXO ,family = binomial(link = 'logit'),data = data.train)
summary(refined.model2)
refined.model57 <- glm(cat2 ~ SEXO ,family = binomial(link = 'logit'),data = data.train)
summary(refined.model57)
refined.model57 <- glm(cat2 ~ SEXO ,family = binomial(link = 'logit'),data = data.train)
summary(refined.model57)
coef(refined.model57)
data$cat2 <- as.factor(data$cat2)
data$cat3 <- as.factor(data$cat3)
data$DENSIDAD <- as.factor(data$DENSIDAD)
data$TAMAMU <- as.factor(data$TAMAMU)
data$SEXO <- as.factor(data$SEXO, c("Mujer","Hombre"))
data$cat2 <- as.factor(data$cat2)
data$cat3 <- as.factor(data$cat3)
data$DENSIDAD <- as.factor(data$DENSIDAD)
data$TAMAMU <- as.factor(data$TAMAMU)
data$SEXO <- as.factor(data$SEXO, labels = c("Mujer","Hombre"))
data$cat2 <- as.factor(data$cat2)
data$cat3 <- as.factor(data$cat3)
data$DENSIDAD <- as.factor(data$DENSIDAD)
data$TAMAMU <- as.factor(data$TAMAMU)
data$SEXO <- as.factor(data$SEXO, levels= c("Mujer","Hombre"))
general_tree <- rpart(cat3 ~ .-cat2, data = data.train, method = "class",
parms = list(split = "information"))
library(rpart)
library(rpart.plot)
library(partykit)
library(party) #Construcción de árboles de inferencia
general_tree <- rpart(cat3 ~ .-cat2, data = data.train, method = "class",
parms = list(split = "information"))
numeric <- data[,c(3, 8,9)]
summary(numeric)
general_tree <- rpart(cat3 ~ ., data = data.train, method = "class",
parms = list(split = "information"))
general_tree <- rpart(cat3 ~ .-cat2, data = data.train, method = "class",
parms = list(split = "information"))
general_tree <- rpart(cat3 ~ ., data = data.train, method = "class",
parms = list(split = "information"))
general_tree <- rpart(cat3 ~ ., data = data.train, method = "class",
parms = list(split = "information"))
print(general_tree)
general_tree <- rpart(cat3 ~ ., data = data.train, method = "class",
parms = list(split = "information"))
print(general_tree)
summary(general_tree)
general_tree$cptable
plotcp(general_tree)
pruned_general_tree <- prune(general_tree, cp = 0.03759398)
pruned_general_tree <- prune(general_tree, cp = 0.017)
prp(pruned_general_tree, type = 2, extra = 104,
fallen.leaves = TRUE, main = "General Decision (Pruned) Tree")
prp(pruned_general_tree, type = 2, extra = 104,
fallen.leaves = TRUE, main = "Árbol general de decisión podado")
plot(as.party(pruned_general_tree))
pred_general_tree <- predict(general_tree, data.test, type = "class")
general_pred_table <- table(data.test$cat3, pred_general_tree, dnn = c("Actual", "Predicted"))
general_pred_table
tr(general_pred_table)
trace(general_pred_table)
diag(general_pred_table)
length(data.test)
dim(data.test)[1]
sum(diag(general_pred_table))/dim(data.test)[1]
pred_general_pruned_tree <- predict(general_pruned_tree, data.test, type = "class")
pred_general_pruned_tree <- predict(pruned_general_tree, data.test, type = "class")
general_pruned_pred_table <- table(data.test$cat3, pred_general_pruned_tree, dnn = c("Actual", "Predicted"))
general_pruned_pred_table
sum(diag(general_pred_table))/dim(data.test)[1]
sum(diag(general_pruned_pred_table))/dim(data.test)[1]
pruned_general_tree <- prune(general_tree, cp = 0.028)
prp(pruned_general_tree, type = 2, extra = 104,
fallen.leaves = TRUE, main = "Árbol general de decisión podado")
pred_general_tree <- predict(general_tree, data.test, type = "class")
general_pred_table <- table(data.test$cat3, pred_general_tree, dnn = c("Actual", "Predicted"))
general_pred_table
pred_general_pruned_tree <- predict(pruned_general_tree, data.test, type = "class")
general_pruned_pred_table <- table(data.test$cat3, pred_general_pruned_tree, dnn = c("Actual", "Predicted"))
general_pruned_pred_table
sum(diag(general_pruned_pred_table))/dim(data.test)[1]
pruned_general_tree <- prune(general_tree, cp = 0.017)
prp(pruned_general_tree, type = 2, extra = 104,
fallen.leaves = TRUE, main = "Árbol general de decisión podado")
pred_general_tree <- predict(general_tree, data.test, type = "class")
general_pred_table <- table(data.test$cat3, pred_general_tree, dnn = c("Actual", "Predicted"))
general_pred_table
sum(diag(general_pred_table))/dim(data.test)[1]
pred_general_pruned_tree <- predict(pruned_general_tree, data.test, type = "class")
general_pruned_pred_table <- table(data.test$cat3, pred_general_pruned_tree, dnn = c("Actual", "Predicted"))
general_pruned_pred_table
sum(diag(general_pruned_pred_table))/dim(data.test)[1]
general_inference_tree <- ctree(cat3~., data = data.train)
plot(general_inference_tree, main = "Árbol general de inferencia")
pred_conditional_general_tree <- predict(general_inference_tree, data.validate, type = "response")
pred_conditional_general_tree <- predict(general_inference_tree, data.test, type = "response")
general_conditional_pred_table <- table(data.test$cat3, pred_conditional_general_tree, dnn = c("Actual", "Predicted"))
general_conditional_pred_table
sum(diag(general_conditional_pred_table))/dim(data.test)[1]
library(glmnet)
library(caret)
model <- train(cat3~., data.train, method = 'glmnet',
tuneGrid = expand.grid(
.alpha = 0:1,
.lambda = 0:30/10))
model
View(model)
plot(model)
coef(model$finalModel, s=model$bestTune$.lambda)
plot(model)
A <- coef(model$finalModel, s=model$bestTune$.lambda)
View(A)
X_train <- model.matrix(cat3 ~., data.training)[-11]
X_train <- model.matrix(cat3 ~., data.train)[-11]
y_train <- data.train$cat3
X_test <- model.matrix(cat3 ~., data.test)[,-11]
y_test <- data.test$cat3
fit = glmnet(X_train, y_train, family = "multinomial", type.multinomial = "grouped")
library(glmnet)
X_train <- model.matrix(cat3 ~., data.train)[-11]
y_train <- data.train$cat3
X_test <- model.matrix(cat3 ~., data.test)[,-11]
y_test <- data.test$cat3
fit = glmnet(X_train, y_train, family = "multinomial", type.multinomial = "grouped")
library(glmnet)
X_train <- model.matrix(cat3 ~., data.train)[,-11]
y_train <- data.train$cat3
X_test <- model.matrix(cat3 ~., data.test)[,-11]
y_test <- data.test$cat3
fit = glmnet(X_train, y_train, family = "multinomial", type.multinomial = "grouped")
cvfit=cv.glmnet(X_train, y_train, family="multinomial", type.multinomial = "grouped", parallel = TRUE)
predict(cvfit, newx = X_test, s = "lambda.min", type = "class")
fit = glmnet(X_train, y_train, family = "multinomial", type.multinomial = "grouped")
cvfit=cv.glmnet(X_train, y_train, family="multinomial", type.multinomial = "grouped", parallel = TRUE)
prediction_cat3 <- predict(cvfit, newx = X_test, s = "lambda.min", type = "class")
(mat_cat3 <- table(data.test$cat2, prediction_cat3, dnn = c("Actual", "Predicted")))
(mat_cat3 <- table(data.test$cat3, prediction_cat3, dnn = c("Actual", "Predicted")))
sum(diag(mat_cat3))/dim(data.test)[1]
coef(cvfit)
selected_tree <- rpart(cat3 ~ TAMAMU + DENSIDAD + SEXO + ESTUD + LAB + REGTEN+ IMPEXAC, data = data.train, method = "class",
parms = list(split = "information"))
print(selected_tree)
summary(selected_tree)
selected_tree$cptable
selected_tree$cptable
plotcp(selected_tree)
plotcp(selected_tree)
pruned_selected_tree <- prune(general_tree, cp = 0.026)
prp(pruned_selected_tree, type = 2, extra = 104,
fallen.leaves = TRUE, main = "Árbol de decisión con variables seleccionasdas podado")
prp(pruned_selected_tree, type = 2, extra = 104,
fallen.leaves = TRUE, main = "Árbol de decisión con variables seleccionasdas podado")
pred_selected_tree <- predict(selected_tree, data.test, type = "class")
selected_pred_table <- table(data.test$cat3, pred_selected_tree, dnn = c("Actual", "Predicted"))
selected_pred_table
sum(diag(selected_pred_table))/dim(data.test)[1]
pred_selected_pruned_tree <- predict(pruned_selected_tree, data.test, type = "class")
selected_pruned_pred_table <- table(data.test$cat3, pred_selected_pruned_tree, dnn = c("Actual", "Predicted"))
selected_pruned_pred_table
sum(diag(selected_pruned_pred_table))/dim(data.test)[1]
X_train
dim(X_train)
X_train[,-15]
library(openxlsx)
data <- read.xlsx("./data/BDexamen2.xlsx")
dim(data)
str(data)
data$cat2 <- as.factor(data$cat2)
data$cat3 <- as.factor(data$cat3)
data$DENSIDAD <- as.factor(data$DENSIDAD)
data$TAMAMU <- as.factor(data$TAMAMU)
data$SEXO <- as.factor(data$SEXO)
data$ESTUD <- as.factor(data$ESTUD)
data$LAB <- as.factor(data$LAB)
data$REGTEN <- as.factor(data$REGTEN)
unique(data$EDAD)
data$EDAD <- as.integer(data$EDAD)
str(data)
numeric <- data[,c(3, 8,9)]
summary(numeric)
