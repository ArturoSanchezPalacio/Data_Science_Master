{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give me some credit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un KPI podría ser la tasa de morosidad. Se busca minimizar este valor. Para ello en base a un conjunto histórico que tiene atributos de clientes que han solicitado un crédito etiquetados según si han sido o no considerados moras. Busco un modelo de que antemano me dé una probabilidad de que el ciente entre en mora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El origen de los datos es la base de datos abierta Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respecto a los datos máximo mínimo elementos nulos tipo de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después análisis exploratio, medias medianas, varianzas, correlaciones... ¿Cuántas variables y de qué tipo (usar Info o describe())?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nota:__ Paquete en R summary tools muy interesante. No hay un equivalente exacto en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra idea son variables combinadas salidas a partir de lo que tenemos y que explican mejor que las variables separadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras ello conviene repetir el análisis exploratorio porque hemos añadido variables. Es __importante__ recomprobar la correlación. Esta fase es la __selección de variable__. Certificar de verdad por qué me quedo con estas variables y no con otras. Lo más sencillo es lasso.\n",
    "En ocasiones se debe normalizar variables.La dummy no hace falta normalizarla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar si los datos están balanceados o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer modelo debe ser sencillo (normalmente una logística) para tener una primera referencia. La aplicamos al conjunto de test y sacamos las métricas: AUC (Curva ROC), F1, Matriz Confusión.\n",
    "A partir de ahí probamos SVM. Métricas etc\n",
    "RF \n",
    "XGBoost\n",
    "\n",
    "Finalmente comparar y conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo el análisis descriptivo en un notebook y luego un notebook por técnica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
