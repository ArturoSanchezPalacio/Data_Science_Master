{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examen Gestión de Información no estructurada\n",
    "__Arturo Sánchez Palacio__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoría"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1.  Pre-procesamiento de textos. Enumere las tareas que lo componen. ¿En qué se diferencian stemming y lematización? Ponga un ejemplo.\n",
    "\n",
    "El preprocesamiento de texto es la tarea previa básica a la minería de textos y permite dejar los textos a estudiar preparados para el análisis. Se compone de las siguientes tareas:\n",
    "\n",
    "* Constitución del corpus.\n",
    "* Detección del idioma.\n",
    "* Segmentación en frases.\n",
    "* Tokenización.\n",
    "* Normalización (Stemming y Formas Canónicas).\n",
    "* Análisis Gramatical.\n",
    "* Análisis Sintáctico.\n",
    "* Shallow Parsing.\n",
    "\n",
    "El stemming consiste en extraer las raíces de las palabras y trabajar con dichas raíces en lugar de las palabras completas a la hora de analizar los documentos. Es un proceso puramente morfológico que no tiene en cuenta el contexto. La lematización por su parte consiste en extraer a partir de una palabra su lema o forma canónica. En este caso sí se tiene en cuenta el contexto que permite en ocasiones desambiguar.\n",
    "\n",
    "El caso no está resulto -> Caso \n",
    "\n",
    "Me caso en Septiembre de 2022 -> Casar\n",
    "\n",
    "El stemming de casar es cas frente a su forma normal que es casar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2. ¿Cuáles son los principales mecanismos de evaluación de un sistema de clasificación atendida? ¿Es suficiente con dar un solo parámetro para ver la bondad de un sistema de clasificación?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez realizada una clasificación se debe emplear el conjunto de validación para la construcción de la matriz de confusión. Esta matriz nos aporta una gran cantidad de información para la calidad del modelo pudiéndose calcular a partir de ella:\n",
    "* la tasa de aciertos (cuántos individuos están bien clasificados entre el total) \n",
    "* la precision indica lo relevante de tus resultados (aciertos positivos contra positivos en total)\n",
    "* el recall indica el porcentaje de resultados relevantes correctamente clasificados (aciertos positivos entre predicciones positivas)\n",
    "\n",
    "La relevancia de estos parámetros se debe a que según lo balanceada que esté la muestra la tasa de acierto nos puede llevar a error. Si tenemos un problema de detección de fraude en el que hay pocos ejemplos de positivo frente a muchos de negativo. Un modelo que clasificara todo como negativo podría tener una tasa de acierta muy alta y sin embargo no sería un buen modelo pues no estaría cumpliendo su misión.\n",
    "\n",
    "Otras métricas interesantes son el diagrama de Precision-Recall o las curvas ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3. Un Banco de Consumo de tamaño medio desea agilizar su proceso de tramitación de quejas y reclamaciones de los clientes. Actualmente el primer paso es una clasificación manual realizada por empleados del banco. Este proceso es lento y tiene un coste alto. ¿Qué sistema propondría usted para mecanizar este procedimiento? Indique si emplearía un software comercial, software de libre distribución o realizaría un programa a medida. Indique también el algoritmo recomendado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de construir un modelo para afrontar este problema optaría por un modelo de clasificación. Si se tratara de un banco joven que no contara con suficientes datos quizá fuera necesario recurrir directamente a un software comercial pues el banco no dispondría de la suficiente información para la construcción de un modelo adecuado. En caso de disponer de dicha información definiría el proyecto según las necesidades de la empresa (quizá interese clasificar las quejas por tema (atención, problemas con la web,...) o por urgencia para su atención (inmediatas, urgentes, leves...). Una vez definidas las categorías entrenaría un modelo de clasificación que se iría revisando periódicamente para su mejora y actualización. Como algoritmo emplearía el Support Vector Machine.\n",
    "\n",
    "A la hora de decidir entre software comercial y software libre esto dependería en gran parte de los recursos humanos del banco dependiendo de su capacidad y costumbre de trabajo con programación. Posiblemente la opción más cauta sería comenzar con software comercial por garantizar su asistencia en todo momento y paralelamente comenzar a desarrollar una solución propia de la empresa.Una vez que esta solución esté depurada se podría prescindir del software logrando una considerable reducción de costes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4. Enumere los principales paquetes open-source de PLN. Describa brevemente la arquitectura de dichos paquetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los principales paquetes open-source de PLN son:\n",
    "* Lucene\n",
    "* Solr\n",
    "* ElasticSearch\n",
    "\n",
    "Todos ellos fundamentados en la arquitectura UIMA. UIMA es una plataforma que busca proveer representaciones comunes de los datos (CAS) para el objeto analizado, coordinar el flujo de trabajo de los motores de análisis y empaquetar motores de análisis en un desarrollo genérico y portable. Es es términos generales una pltaforma que auna varios motores de análisis con el fin de extraer información valiosa a partir de datos no estructurados.\n",
    "\n",
    "Los dos conceptos clave de la arquitectura UIMA son:\n",
    "* __Motor de Análisis__. Programa que analiza los elementos e infiere información a partir de ellos. Se construyen a partir de bloquees llamados anotadores.\n",
    "* __Anotador__. Un anotador es un componente que contiene análisis lógicos y emplea todos los recursos necesarios para ejecutar ese logicial. Realiza tareas de análisis lingüístico obteniendo y registrando anotaciones.\n",
    "\n",
    "La UIMA define una estructura común de análisis (CAS) para que los anotadores representen y compartan su información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5. ¿Cuáles son los algoritmos más frecuentes que se utilizan para la extracción de tópicos? ¿Qué librerías Python son las más utilizadas que implementen dichos algoritmos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos que más se utilizan para el modelado de tópicos son:\n",
    "* Latent Dirichlet Allocation (LDA).\n",
    "* Probabilistic Latent Semantic Analysis (PLSA).\n",
    "* Correlated Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La biblioteca más empleada en Python para el modelo de tópicos es Gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan a continuación los módulos utilizados para este examen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import textacy, spacy, nltk\n",
    "from stop_words import get_stop_words\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1. Realize un preprocesamiento del siguiente texto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se carga el texto vía string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zambrano = \"\"\"María Zambrano (1904, Vélez Málaga-1991, Madrid) figura en la cima de\n",
    "la filosofía del pensamiento español. Desde 1909 a 1924 vivió en Segovia,\n",
    "donde conoció a Antonio Machado. Discípula predilecta de Ortega y\n",
    "Gasset, asistió también a clases de García Morente, Manuel Bartolomé\n",
    "Cossío y Xavier Zubiri. Empezó a publicar artículos en 1928 y su primer\n",
    "libro, Horizonte del liberalimo data de 1930. Ya en la República, participó\n",
    "en las Misiones Pedagógicas. Su exilio la llevó por Chile, México, Cuba,\n",
    "Puerto Rico, Roma, París y Suiza.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detectamos el idioma del texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textacy.text_utils.detect_language(Zambrano)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se empleará Spacy por tratarse de un texto en castellano. Para ello se procede a la carga del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procesa el texto según este modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zambrano_proc = nlp(Zambrano)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se presentan a continuación las frases del texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frases:\n",
      "María Zambrano (1904, Vélez Málaga-1991, Madrid) figura en la cima de\n",
      "la filosofía del pensamiento español.\n",
      "Desde 1909 a 1924 vivió en Segovia,\n",
      "donde conoció a Antonio Machado.\n",
      "Discípula predilecta de Ortega y\n",
      "Gasset, asistió también a clases de García Morente, Manuel Bartolomé\n",
      "Cossío y Xavier Zubiri.\n",
      "Empezó a publicar artículos en 1928 y su primer\n",
      "libro, Horizonte del liberalimo data de 1930.\n",
      "Ya en la República, participó\n",
      "en las Misiones Pedagógicas.\n",
      "Su exilio la llevó por Chile, México, Cuba,\n",
      "Puerto Rico, Roma, París y Suiza.\n",
      "\n",
      " El texto consta de 6 frases.\n"
     ]
    }
   ],
   "source": [
    "print(\"Frases:\")\n",
    "n_frases = 0\n",
    "for sent in Zambrano_proc.sents:\n",
    "    print(sent)\n",
    "    n_frases=n_frases + 1\n",
    "print(\"\\n El texto consta de\",n_frases,\"frases.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se presenta a continuación la lista de palabras del texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras:\n",
      "María\n",
      "Zambrano\n",
      "(\n",
      "1904\n",
      ",\n",
      "Vélez\n",
      "Málaga-1991\n",
      ",\n",
      "Madrid\n",
      ")\n",
      "figura\n",
      "en\n",
      "la\n",
      "cima\n",
      "de\n",
      "\n",
      "\n",
      "la\n",
      "filosofía\n",
      "del\n",
      "pensamiento\n",
      "español\n",
      ".\n",
      "Desde\n",
      "1909\n",
      "a\n",
      "1924\n",
      "vivió\n",
      "en\n",
      "Segovia\n",
      ",\n",
      "\n",
      "\n",
      "donde\n",
      "conoció\n",
      "a\n",
      "Antonio\n",
      "Machado\n",
      ".\n",
      "Discípula\n",
      "predilecta\n",
      "de\n",
      "Ortega\n",
      "y\n",
      "\n",
      "\n",
      "Gasset\n",
      ",\n",
      "asistió\n",
      "también\n",
      "a\n",
      "clases\n",
      "de\n",
      "García\n",
      "Morente\n",
      ",\n",
      "Manuel\n",
      "Bartolomé\n",
      "\n",
      "\n",
      "Cossío\n",
      "y\n",
      "Xavier\n",
      "Zubiri\n",
      ".\n",
      "Empezó\n",
      "a\n",
      "publicar\n",
      "artículos\n",
      "en\n",
      "1928\n",
      "y\n",
      "su\n",
      "primer\n",
      "\n",
      "\n",
      "libro\n",
      ",\n",
      "Horizonte\n",
      "del\n",
      "liberalimo\n",
      "data\n",
      "de\n",
      "1930\n",
      ".\n",
      "Ya\n",
      "en\n",
      "la\n",
      "República\n",
      ",\n",
      "participó\n",
      "\n",
      "\n",
      "en\n",
      "las\n",
      "Misiones\n",
      "Pedagógicas\n",
      ".\n",
      "Su\n",
      "exilio\n",
      "la\n",
      "llevó\n",
      "por\n",
      "Chile\n",
      ",\n",
      "México\n",
      ",\n",
      "Cuba\n",
      ",\n",
      "\n",
      "\n",
      "Puerto\n",
      "Rico\n",
      ",\n",
      "Roma\n",
      ",\n",
      "París\n",
      "y\n",
      "Suiza\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "print(\"Palabras:\")\n",
    "for palabra in Zambrano_proc:\n",
    "    print(palabra.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2. Extraiga y escriba por pantalla las formas normales y la categoría gramatical de cada una de las palabras del texto anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formas normales junto a su categoría gramatical:\n",
      "María PROPN\n",
      "Zambrano PROPN\n",
      "( PUNCT\n",
      "1904 NOUN\n",
      ", PUNCT\n",
      "Vélez PROPN\n",
      "Málaga-1991 PROPN\n",
      ", PUNCT\n",
      "Madrid PROPN\n",
      ") PUNCT\n",
      "figurar VERB\n",
      "en ADP\n",
      "lo DET\n",
      "cima NOUN\n",
      "de ADP\n",
      "\n",
      " SPACE\n",
      "lo DET\n",
      "filosofía NOUN\n",
      "del ADP\n",
      "pensamiento NOUN\n",
      "español ADJ\n",
      ". PUNCT\n",
      "Desde ADP\n",
      "1909 NOUN\n",
      "a ADP\n",
      "1924 NOUN\n",
      "vivir VERB\n",
      "en ADP\n",
      "Segovia PROPN\n",
      ", PUNCT\n",
      "\n",
      " SPACE\n",
      "donde PRON\n",
      "conocer VERB\n",
      "a ADP\n",
      "Antonio PROPN\n",
      "Machado PROPN\n",
      ". PUNCT\n",
      "Discípula VERB\n",
      "predilecto ADJ\n",
      "de ADP\n",
      "Ortega PROPN\n",
      "y CONJ\n",
      "\n",
      " SPACE\n",
      "Gasset PROPN\n",
      ", PUNCT\n",
      "asistir VERB\n",
      "también ADV\n",
      "a ADP\n",
      "clase NOUN\n",
      "de ADP\n",
      "García PROPN\n",
      "Morente PROPN\n",
      ", PUNCT\n",
      "Manuel PROPN\n",
      "Bartolomé PROPN\n",
      "\n",
      " SPACE\n",
      "Cossío PROPN\n",
      "y CONJ\n",
      "Xavier PROPN\n",
      "Zubiri PROPN\n",
      ". PUNCT\n",
      "Empezó AUX\n",
      "a ADP\n",
      "publicar VERB\n",
      "artículo NOUN\n",
      "en ADP\n",
      "1928 NOUN\n",
      "y CONJ\n",
      "su DET\n",
      "﻿1 ADJ\n",
      "\n",
      " SPACE\n",
      "librar NOUN\n",
      ", PUNCT\n",
      "Horizonte PROPN\n",
      "del ADP\n",
      "liberalimo ADJ\n",
      "datar VERB\n",
      "de ADP\n",
      "1930 NOUN\n",
      ". PUNCT\n",
      "Ya ADV\n",
      "en ADP\n",
      "lo DET\n",
      "República PROPN\n",
      ", PUNCT\n",
      "participar VERB\n",
      "\n",
      " SPACE\n",
      "en ADP\n",
      "los DET\n",
      "Misiones PROPN\n",
      "Pedagógicas PROPN\n",
      ". PUNCT\n",
      "Su DET\n",
      "exiliar NOUN\n",
      "lo PRON\n",
      "llevar VERB\n",
      "por ADP\n",
      "Chile PROPN\n",
      ", PUNCT\n",
      "México PROPN\n",
      ", PUNCT\n",
      "Cuba PROPN\n",
      ", PUNCT\n",
      "\n",
      " SPACE\n",
      "Puerto PROPN\n",
      "Rico PROPN\n",
      ", PUNCT\n",
      "Roma PROPN\n",
      ", PUNCT\n",
      "París PROPN\n",
      "y CONJ\n",
      "Suiza PROPN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "print(\"Formas normales junto a su categoría gramatical:\")\n",
    "for palabra in Zambrano_proc:\n",
    "    print(palabra.lemma_, palabra.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3. Realice una extracción de entidades del texto anterior. Deben aparecer al menos entidades de tipo persona, localización y organización. Comente los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Entidades:\n",
      "María Zambrano PER\n",
      "Vélez Málaga-1991 MISC\n",
      "Madrid LOC\n",
      "Segovia LOC\n",
      "Antonio Machado PER\n",
      "Discípula PER\n",
      "Ortega PER\n",
      "García Morente PER\n",
      "Manuel Bartolomé\n",
      "Cossío PER\n",
      "Xavier Zubiri PER\n",
      "Empezó PER\n",
      "Horizonte del liberalimo data MISC\n",
      "Ya en la República MISC\n",
      "Misiones Pedagógicas MISC\n",
      "Chile LOC\n",
      "México LOC\n",
      "Cuba LOC\n",
      "Puerto Rico LOC\n",
      "Roma LOC\n",
      "París LOC\n",
      "Suiza LOC\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Entidades:\")\n",
    "for entidad in Zambrano_proc.ents:\n",
    "    print(entidad.text, entidad.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La detección de entidades es bastante buena detecta y acierta con todas las localizaciones a excepción de Vélez Málaga quizá por la confusión que genera la fecha. \n",
    "\n",
    "En cuanto a personas su acierto es más parcial. Si bien detecta a todas las personas mencionadas algunas como la propia María Zambrano, Antonio Machado o García Morente se detectan como un única entidad mientras que en Ortega y Gasset  solo detecta Ortega y en Manuel Bartolomé Cossío detecta como dos entidades Manuel Bartolomé y Cossío.\n",
    "\n",
    "No detecta entidades de tipo organización pues no aparece ninguna en el texto.\n",
    "\n",
    "Por último algunas entidades se catalogan en miscelánea (cabe suponer que por el uso de mayúsculas) como son \"Ya en la República\". (Si el ya se introduce en minúsculas solo capta República), Vélez Málaga-1991 por lo antes comentado o Misiones Pegadógicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4. Extraiga los ficheros que se encuentran en el archivo docus.zip en un directorio. Léalos desde su notebook y realice las tareas de pre-procesamiento que considere necesarias para abordar una extracción de tópicos. Genere 3 tópicos y saque por pantalla la lista con los 5 términos más frecuentes de cada tópico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede en primer lugar a la construcción del corpus a partir de los archivos presentes en el fichero comprimido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_dir = \"./docus/\"\n",
    "documentos = PlaintextCorpusReader(docs_dir, '.*') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los documentos presentes en el directorio son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0001.txt', '0002.txt', '0003.txt', '0004.txt', '0005.txt', '0006.txt', '0007.txt', '0008.txt', '0009.txt', '0010.txt', '0011.txt', '0012.txt', '0013.txt', '0014.txt', '0015.txt']\n"
     ]
    }
   ],
   "source": [
    "print(documentos.fileids()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a detectar el idioma de los documentos con el fin de elegir el modelo para la extracción de tópicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001.txt es\n",
      "0002.txt es\n",
      "0003.txt es\n",
      "0004.txt es\n",
      "0005.txt es\n",
      "0006.txt pt\n",
      "0007.txt es\n",
      "0008.txt es\n",
      "0009.txt es\n",
      "0010.txt es\n",
      "0011.txt es\n",
      "0012.txt es\n",
      "0013.txt es\n",
      "0014.txt es\n",
      "0015.txt es\n"
     ]
    }
   ],
   "source": [
    "for titulo in documentos.fileids():\n",
    "    print(titulo, textacy.text_utils.detect_language(documentos.raw(fileids=titulo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecta español en todos los textos exceptuando uno que aparece en portugues. Este texto se comprueba manualmente viendo que también se encuentra en castellano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vargas Llosa anuncia un libro sobre el golpe militar auspiciado por la CIA en Guatemala en 1954'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentos.raw(fileids=\"0006.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecho esto se elige el modelo de Spacy para extracción de tópicos y se procede al procesado de los textos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm') #Es redundante ya se hizo antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = []\n",
    "for titulo in documentos.fileids():\n",
    "    doc_list.append(documentos.raw(fileids=titulo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza un análisis LDA. Para ello es necesario vectorizar el documento lo que requiere la transformación a minúsculas de todas las palabras, el paso a forma normal y la eliminación de las palabras vacías.\n",
    "\n",
    "Se carga en primer lugar la lista de palabras vacías en español:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_stop = get_stop_words('es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se recorre cada documentos pasando las palabras a minúsculas, obteniendo las formas normales y añadiéndolas a la lista si no son palabras vacías. Además se añade como restricción que tenga longitud mayor que uno porque lo más probable es que sea una palabra vacía o un signo de puntuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = []\n",
    "palabras = []\n",
    "\n",
    "for doc in doc_list:\n",
    "    doc_min = doc.lower()\n",
    "    doc = nlp(doc_min)\n",
    "    for token in doc:\n",
    "        if (not token.lemma_ in es_stop) and (len(token.lemma_)>1):\n",
    "            palabras.append(token.lemma_)\n",
    "    textos.append(palabras)\n",
    "    palabras = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En textos se almacenan los documentos ya procesados. Tras ello se procede a la construcción del diccionario de términos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(textos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras esto se genera la matriz de términos documentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(texto) for texto in textos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se construye el modelo LDA. Se fijan tres clusters porque son en teoría los presentes en los documentos: baloncesto, Literatura y tecnología."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se visualizan los cinco términos más frecuentes en cada tópico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminos_topic = ldamodel.print_topics(num_topics=3, num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.025*\"ordenador\" + 0.025*\"principal\" + 0.024*\"madrid\" + 0.014*\"nuevo\" + 0.014*\"entrar\"')\n",
      "(1, '0.020*\"librar\" + 0.020*\"parir\" + 0.020*\"portugal\" + 0.012*\"apple\" + 0.012*\"canasta\"')\n",
      "(2, '0.029*\"temporada\" + 0.023*\"baloncesto\" + 0.023*\"parir\" + 0.016*\"olympiacos\" + 0.016*\"haber\"')\n"
     ]
    }
   ],
   "source": [
    "for terminos in terminos_topic:\n",
    "    print(terminos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5. Obtenga el resultado gráfico del análisis mediante la librería pyLDAvis. Comente los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arturosanchezpalacio/Entornos virtuales/notebooks/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "data = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el232948645747123818961841\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el232948645747123818961841_data = {\"mdsDat\": {\"x\": [0.08192041309413728, -0.08486976312707108, 0.002949350032933779], \"y\": [-0.03967860291653401, -0.03568085967109404, 0.07535946258762806], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [46.3189582824707, 31.782623291015625, 21.89841651916504]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.739816427230835, 1.4752352237701416, 1.475235104560852, 1.475235104560852, 1.4752120971679688, 1.4751142263412476, 0.8428980708122253, 0.8428980708122253, 0.8428980708122253, 0.8428980708122253, 0.8428980112075806, 0.8428980112075806, 0.8428980112075806, 0.8428980112075806, 0.8428980112075806, 0.8428980112075806, 0.8428980112075806, 0.8428651094436646, 0.8428650498390198, 0.8428651094436646, 0.8428651094436646, 0.8428651094436646, 0.8428651094436646, 0.8428651094436646, 0.8428650498390198, 0.8428650498390198, 0.8428650498390198, 0.842864990234375, 0.842864990234375, 0.842864990234375, 0.842864990234375, 2.1138651371002197, 1.4745022058486938, 2.1043500900268555, 0.842864990234375, 1.4600536823272705, 0.8429430723190308, 0.842864990234375, 1.2920711040496826, 0.7382721304893494, 0.738271951675415, 0.7382718920707703, 0.7382718920707703, 0.738271951675415, 0.738271951675415, 0.738271951675415, 0.7382718920707703, 0.7382718324661255, 0.7382718324661255, 0.7382717728614807, 0.7382717728614807, 0.7382717728614807, 0.7382717728614807, 0.7382717728614807, 0.7382717728614807, 0.7382716536521912, 0.7382165193557739, 0.7382165193557739, 0.7382165193557739, 0.7382165193557739, 0.7382165193557739, 0.7382165193557739, 0.7382165193557739, 0.7382165193557739, 0.7382165193557739, 0.7382165193557739, 0.7382165193557739, 0.7381503582000732, 1.2949280738830566, 1.2948896884918213, 0.742216169834137, 0.7404148578643799, 0.7397213578224182, 0.7392905950546265, 0.7392904758453369, 0.7388499975204468, 0.7383527159690857, 0.7382664680480957, 1.07633638381958, 0.6149910688400269, 0.6149910092353821, 0.6149910092353821, 0.6149910688400269, 0.6149910688400269, 0.6149910092353821, 0.6149780750274658, 0.6149778962135315, 0.6149779558181763, 0.6149779558181763, 0.6149778962135315, 0.6149779558181763, 0.6149734854698181, 0.6149734854698181, 0.6149734854698181, 0.6149734854698181, 0.6149734854698181, 0.6149734854698181, 0.6149734854698181, 0.6149681210517883, 0.6149681210517883, 0.6149681210517883, 0.6149681210517883, 0.6149681210517883, 0.6149681210517883, 1.078568935394287, 0.6160224080085754, 0.6150305271148682, 0.6197276711463928, 1.090105414390564, 0.6171050667762756, 0.6174384951591492, 0.6171050667762756, 0.615598201751709, 0.615515947341919, 0.6153894066810608, 0.6152517795562744], \"Term\": [\"madrid\", \"principal\", \"temporada\", \"librar\", \"portugal\", \"analizar\", \"acercar\", \"tablet\", \"diferenciar\", \"mundo\", \"generaci\\u00f3n\", \"semifinal\", \"s\\u00e1bado\", \"arrancar\", \"off\", \"terminar\", \"play\", \"atacar\", \"dell\", \"empresarial\", \"modelo\", \"querer\", \"sobremesa\", \"preocupaci\\u00f3n\", \"luis\", \"jos\\u00e9\", \"garc\\u00eda\", \"visitar\", \"privar\", \"comprar\", \"temporada\", \"olympiacos\", \"panathinaikos\", \"haber\", \"equipo\", \"presentar\", \"pol\\u00e9mico\", \"jugar\", \"ganar\", \"duro\", \"enfrentamiento\", \"punto\", \"tener\", \"griego\", \"derbi\", \"20\", \"negar\", \"peruano\", \"tiempo\", \"edici\\u00f3n\", \"t\\u00edtulo\", \"cuyo\", \"novelar\", \"publicar\", \"citar\", \"alusi\\u00f3n\", \"alfaguara\", \"recio\", \"\\u00e1vila\", \"ayer\", \"santo\", \"baloncesto\", \"\\u00faltimo\", \"parir\", \"teresa\", \"ordenador\", \"anunciar\", \"a\\u00f1o\", \"portugal\", \"sibila\", \"recogida\", \"agustina\", \"recopilaci\\u00f3n\", \"luso\", \"grande\", \"conocido\", \"siglo\", \"xix\", \"gran\", \"bessa\", \"xx\", \"p\\u00fablico\", \"morir\", \"costumbre\", \"luir\", \"ra\\u00edz\", \"estudiar\", \"l\\u00edneo\", \"reunir\", \"reglar\", \"mayor\", \"nba\", \"conveniencia\", \"alejar\", \"aplicar\", \"triple\", \"distanciar\", \"militar\", \"librar\", \"parir\", \"apple\", \"canasta\", \"entrar\", \"escritor\", \"hacer\", \"cancha\", \"acb\", \"anunciar\", \"madrid\", \"analizar\", \"mundo\", \"acercar\", \"tablet\", \"diferenciar\", \"generaci\\u00f3n\", \"semifinal\", \"terminar\", \"arrancar\", \"off\", \"play\", \"s\\u00e1bado\", \"querer\", \"preocupaci\\u00f3n\", \"modelo\", \"empresarial\", \"dell\", \"atacar\", \"sobremesa\", \"comprar\", \"jos\\u00e9\", \"garc\\u00eda\", \"luis\", \"privar\", \"visitar\", \"principal\", \"port\\u00e1til\", \"acb\", \"nuevo\", \"ordenador\", \"feriar\", \"entrar\", \"libro\", \"\\u00faltimo\", \"pr\\u00f3ximo\", \"do\", \"ligar\"], \"Total\": [1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.078399419784546, 1.81376051902771, 1.8137603998184204, 1.8137603998184204, 1.8137561082839966, 1.8137353658676147, 1.181431531906128, 1.181431531906128, 1.181431531906128, 1.181431531906128, 1.181431531906128, 1.181431531906128, 1.181431531906128, 1.181431531906128, 1.181431531906128, 1.181431531906128, 1.181431531906128, 1.1814264059066772, 1.1814264059066772, 1.1814265251159668, 1.1814265251159668, 1.1814265251159668, 1.1814265251159668, 1.1814265251159668, 1.1814264059066772, 1.1814264059066772, 1.1814264059066772, 1.1814264059066772, 1.1814264059066772, 1.1814265251159668, 1.1814265251159668, 3.462524175643921, 2.2749390602111816, 3.5532402992248535, 1.1814265251159668, 3.285649299621582, 1.7351977825164795, 1.1814265251159668, 1.6567338705062866, 1.1029390096664429, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029388904571533, 1.1029369831085205, 1.1029369831085205, 1.1029369831085205, 1.1029369831085205, 1.1029369831085205, 1.1029369831085205, 1.1029369831085205, 1.1029369831085205, 1.1029369831085205, 1.10293710231781, 1.10293710231781, 1.1029329299926758, 2.118591785430908, 3.5532402992248535, 1.734554409980774, 1.7348740100860596, 2.1955606937408447, 1.735075831413269, 1.7350759506225586, 1.7351254224777222, 1.5643340349197388, 1.7351977825164795, 1.47190260887146, 1.0105457305908203, 1.0105457305908203, 1.0105457305908203, 1.0105457305908203, 1.0105457305908203, 1.0105457305908203, 1.010549545288086, 1.010549545288086, 1.010549545288086, 1.010549545288086, 1.010549545288086, 1.010549545288086, 1.0105504989624023, 1.0105504989624023, 1.0105504989624023, 1.0105504989624023, 1.0105504989624023, 1.0105504989624023, 1.0105504989624023, 1.0105512142181396, 1.0105513334274292, 1.0105513334274292, 1.0105513334274292, 1.0105513334274292, 1.0105513334274292, 2.103379726409912, 1.5641372203826904, 1.5643340349197388, 1.6410605907440186, 3.285649299621582, 1.642052412033081, 2.1955606937408447, 1.642052412033081, 2.2749390602111816, 1.6426496505737305, 1.6427013874053955, 1.6427513360977173], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6531000137329102, 0.5630000233650208, 0.5630000233650208, 0.5630000233650208, 0.5630000233650208, 0.5630000233650208, 0.4320000112056732, 0.4320000112056732, 0.4320000112056732, 0.4320000112056732, 0.4320000112056732, 0.4320000112056732, 0.4320000112056732, 0.4320000112056732, 0.4320000112056732, 0.4320000112056732, 0.4320000112056732, 0.4318999946117401, 0.4318999946117401, 0.4318999946117401, 0.4318999946117401, 0.4318999946117401, 0.4318999946117401, 0.4318999946117401, 0.4318999946117401, 0.4318999946117401, 0.4318999946117401, 0.4318999946117401, 0.4318999946117401, 0.4318999946117401, 0.4318999946117401, 0.2761000096797943, 0.335999995470047, 0.24580000340938568, 0.4318999946117401, -0.04149999842047691, 0.047600001096725464, 0.4318999946117401, 0.897599995136261, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.7447999715805054, 0.744700014591217, 0.6539999842643738, 0.13680000603199005, 0.29739999771118164, 0.2948000133037567, 0.05829999968409538, 0.2930999994277954, 0.2930999994277954, 0.29249998927116394, 0.3955000042915344, 0.29170000553131104, 1.2058000564575195, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 1.0220999717712402, 0.8507999777793884, 0.586899995803833, 0.5852000117301941, 0.5449000000953674, 0.4154999852180481, 0.5400999784469604, 0.2500999867916107, 0.5400999784469604, 0.21160000562667847, 0.5371999740600586, 0.536899983882904, 0.5367000102996826], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.5257999897003174, -4.144899845123291, -4.144899845123291, -4.144899845123291, -4.144899845123291, -4.144999980926514, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -4.704599857330322, -3.7852001190185547, -4.145400047302246, -3.7897000312805176, -4.704599857330322, -4.155200004577637, -4.704500198364258, -4.704599857330322, -3.9007999897003174, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.4604997634887695, -4.460599899291992, -4.460599899291992, -4.460599899291992, -4.460599899291992, -4.460599899291992, -4.460599899291992, -4.460599899291992, -4.460599899291992, -4.460599899291992, -4.460599899291992, -4.460599899291992, -4.460700035095215, -3.8986001014709473, -3.8986001014709473, -4.4552001953125, -4.457600116729736, -4.458499908447266, -4.459099769592285, -4.459099769592285, -4.459700107574463, -4.460400104522705, -4.4604997634887695, -3.7109999656677246, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -4.270699977874756, -3.708899974822998, -4.269000053405762, -4.270599842071533, -4.263000011444092, -3.6982998847961426, -4.267300128936768, -4.26669979095459, -4.267300128936768, -4.269700050354004, -4.269800186157227, -4.269999980926514, -4.270299911499023]}, \"token.table\": {\"Topic\": [1, 2, 3, 3, 2, 2, 1, 1, 3, 1, 2, 2, 1, 2, 3, 3, 1, 1, 1, 2, 3, 2, 1, 2, 1, 2, 1, 3, 2, 2, 2, 1, 3, 1, 3, 2, 1, 3, 1, 1, 3, 1, 1, 2, 3, 1, 1, 2, 2, 1, 3, 1, 3, 3, 2, 2, 1, 1, 1, 2, 3, 1, 2, 3, 1, 3, 1, 3, 2, 3, 2, 2, 3, 2, 2, 3, 2, 3, 2, 1, 1, 1, 3, 3, 1, 1, 2, 3, 1, 1, 2, 1, 3, 1, 2, 2, 3, 3, 1, 1, 3, 3, 1, 3, 1, 1, 2, 3, 2, 1, 2, 2, 2, 2, 1, 3, 2, 2, 3, 3, 3, 1, 1, 1, 3, 1, 2, 1, 3, 2, 2, 1, 1, 3], \"Freq\": [0.846430778503418, 0.6392496824264526, 0.6392496824264526, 0.9895642995834351, 0.9066685438156128, 0.906670093536377, 0.8464344143867493, 0.8464344143867493, 0.9895642995834351, 0.5763031840324402, 0.5763031840324402, 0.906670093536377, 0.5765169262886047, 0.5765169262886047, 0.989560604095459, 0.9895596504211426, 0.8464343547821045, 0.8464343547821045, 0.5776132941246033, 0.28880664706230164, 0.28880664706230164, 0.9066685438156128, 0.576410710811615, 0.576410710811615, 0.5763272047042847, 0.5763272047042847, 0.8464344143867493, 0.9895589351654053, 0.9066685438156128, 0.906670093536377, 0.9066685438156128, 0.8464343547821045, 0.9895596504211426, 0.846430778503418, 0.9895642995834351, 0.9066700339317322, 0.6087533831596375, 0.6087533831596375, 0.846430778503418, 0.8464343547821045, 0.9895596504211426, 0.846430778503418, 0.45546451210975647, 0.45546451210975647, 0.45546451210975647, 0.5513420701026917, 0.5763437151908875, 0.5763437151908875, 0.906670093536377, 0.6089939475059509, 0.6089939475059509, 0.846430778503418, 0.9895588159561157, 0.9895642995834351, 0.9066685438156128, 0.9066685438156128, 0.846430778503418, 0.5513407588005066, 0.5763436555862427, 0.5763436555862427, 0.9895588159561157, 0.846430778503418, 0.47201165556907654, 0.47201165556907654, 0.6089939475059509, 0.6089939475059509, 0.6087348461151123, 0.6087348461151123, 0.9066685438156128, 0.9895588159561157, 0.9066685438156128, 0.906670093536377, 0.6793927550315857, 0.906670093536377, 0.9066734313964844, 0.9895596504211426, 0.9066685438156128, 0.9895642995834351, 0.906670093536377, 0.846430778503418, 0.8464343547821045, 0.609362006187439, 0.609362006187439, 0.989560604095459, 0.5513406991958618, 0.30435383319854736, 0.30435383319854736, 0.30435383319854736, 0.5513407588005066, 0.5628665089607239, 0.28143325448036194, 0.8464344143867493, 0.989560604095459, 0.846430778503418, 0.6035972237586975, 0.6393300890922546, 0.6393300890922546, 0.9895596504211426, 0.5513483285903931, 0.4754253327846527, 0.4754253327846527, 0.9895588159561157, 0.6087725162506104, 0.6087725162506104, 0.8464343547821045, 0.846430778503418, 0.9066685438156128, 0.9895596504211426, 0.9066685438156128, 0.8464344143867493, 0.9066685438156128, 0.9066685438156128, 0.906670093536377, 0.906670093536377, 0.8464343547821045, 0.989560604095459, 0.9066684246063232, 0.9066685438156128, 0.9895596504211426, 0.989560604095459, 0.9895642995834351, 0.974532425403595, 0.846430778503418, 0.8464343547821045, 0.989560604095459, 0.8464344143867493, 0.9066700339317322, 0.8464343547821045, 0.9895588159561157, 0.9066685438156128, 0.9066685438156128, 0.8464344143867493, 0.43957221508026123, 0.43957221508026123], \"Term\": [\"20\", \"acb\", \"acb\", \"acercar\", \"agustina\", \"alejar\", \"alfaguara\", \"alusi\\u00f3n\", \"analizar\", \"anunciar\", \"anunciar\", \"aplicar\", \"apple\", \"apple\", \"arrancar\", \"atacar\", \"ayer\", \"a\\u00f1o\", \"baloncesto\", \"baloncesto\", \"baloncesto\", \"bessa\", \"canasta\", \"canasta\", \"cancha\", \"cancha\", \"citar\", \"comprar\", \"conocido\", \"conveniencia\", \"costumbre\", \"cuyo\", \"dell\", \"derbi\", \"diferenciar\", \"distanciar\", \"do\", \"do\", \"duro\", \"edici\\u00f3n\", \"empresarial\", \"enfrentamiento\", \"entrar\", \"entrar\", \"entrar\", \"equipo\", \"escritor\", \"escritor\", \"estudiar\", \"feriar\", \"feriar\", \"ganar\", \"garc\\u00eda\", \"generaci\\u00f3n\", \"gran\", \"grande\", \"griego\", \"haber\", \"hacer\", \"hacer\", \"jos\\u00e9\", \"jugar\", \"librar\", \"librar\", \"libro\", \"libro\", \"ligar\", \"ligar\", \"luir\", \"luis\", \"luso\", \"l\\u00edneo\", \"madrid\", \"mayor\", \"militar\", \"modelo\", \"morir\", \"mundo\", \"nba\", \"negar\", \"novelar\", \"nuevo\", \"nuevo\", \"off\", \"olympiacos\", \"ordenador\", \"ordenador\", \"ordenador\", \"panathinaikos\", \"parir\", \"parir\", \"peruano\", \"play\", \"pol\\u00e9mico\", \"portugal\", \"port\\u00e1til\", \"port\\u00e1til\", \"preocupaci\\u00f3n\", \"presentar\", \"principal\", \"principal\", \"privar\", \"pr\\u00f3ximo\", \"pr\\u00f3ximo\", \"publicar\", \"punto\", \"p\\u00fablico\", \"querer\", \"ra\\u00edz\", \"recio\", \"recogida\", \"recopilaci\\u00f3n\", \"reglar\", \"reunir\", \"santo\", \"semifinal\", \"sibila\", \"siglo\", \"sobremesa\", \"s\\u00e1bado\", \"tablet\", \"temporada\", \"tener\", \"teresa\", \"terminar\", \"tiempo\", \"triple\", \"t\\u00edtulo\", \"visitar\", \"xix\", \"xx\", \"\\u00e1vila\", \"\\u00faltimo\", \"\\u00faltimo\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el232948645747123818961841\", ldavis_el232948645747123818961841_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el232948645747123818961841\", ldavis_el232948645747123818961841_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el232948645747123818961841\", ldavis_el232948645747123818961841_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo devuelve tres tópicos que no se corresponden con los esperados a priori: Baloncesto, Literatura y Ordenadores. Por las palabras que aparecen en cada grupo se puede observar que en todos ellos se entremezclan textos de los tres temas. Los clusters se encuentran separados entre ellos por el empleo de los distintos términos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
